{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning Transformer Models on SmellyCode++ Dataset\n",
    "\n",
    "In this notebook, we will fine-tune selected transformer models on the task of code smell detection using source code snippets from the `SmellyCode++` dataset. Specifically, we will use the dataset we prepared earlier (`merged_for_training.csv`) and filter it to include only entries originating from `SmellyCode++`.\n",
    "\n",
    "We will train each model to perform **multi-label classification** on the following code smell categories:\n",
    "\n",
    "- Long Method\n",
    "- God Class / Large Class\n",
    "- Feature Envy\n",
    "- Data Class\n",
    "- Clean\n",
    "\n",
    "The selected models for fine-tuning are:\n",
    "\n",
    "- **CodeBERT** (`microsoft/codebert-base`)\n",
    "- **GraphCodeBERT** (`microsoft/graphcodebert-base`)\n",
    "- **CodeT5** (`Salesforce/codet5-base`)\n",
    "\n",
    "We will follow the steps below:\n",
    "1. Load and filter the dataset\n",
    "2. Tokenize source code\n",
    "3. Format data for multi-label classification\n",
    "4. Fine-tune selected transformer models\n",
    "5. Evaluate and compare model performance"
   ],
   "id": "bb8305d5f8fff3f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:33:33.947386Z",
     "start_time": "2025-11-13T14:33:28.397098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.training.data_utils import load_and_prepare_dataset\n",
    "\n",
    "df, label_cols = load_and_prepare_dataset(\"../data/processed/merged_for_training.csv\")\n",
    "\n",
    "# Display class distribution\n",
    "print(\"Number of samples:\", len(df))\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df[label_cols].sum())"
   ],
   "id": "ed32ef58d937feac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 86043\n",
      "\n",
      "Class distribution:\n",
      "Long Method         1252\n",
      "God/Large Class     3467\n",
      "Feature Envy        1596\n",
      "Data Class          2628\n",
      "Clean              78109\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tokenization Strategy\n",
    "\n",
    "Each of the transformer models requires source code to be tokenized in a specific way, depending on its architecture and tokenizer. We will use the HuggingFace `transformers` library to load the correct tokenizer for each model.\n",
    "\n",
    "We will use the `Code` column as input text and the five binary smell indicators as targets. As this is a **multi-label classification task**, the targets will be represented as binary vectors (e.g., `[1, 0, 1, 0, 0]`).\n",
    "\n",
    "The tokenization will:\n",
    "- truncate long inputs to the model's `max_length`\n",
    "- pad shorter inputs\n",
    "- return `input_ids` and `attention_mask` for training"
   ],
   "id": "14ed977a8dc93cd6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine-tune CodeBERT",
   "id": "62fcef06fc01b173"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.training.train_codebert import train_multilabel_transformer\n",
    "\n",
    "train_multilabel_transformer(\n",
    "    model_name=\"microsoft/codebert-base\",\n",
    "    df=df,\n",
    "    label_cols=[\"Long Method\", \"God/Large Class\", \"Feature Envy\", \"Data Class\", \"Clean\"],\n",
    "    output_dir=\"../models/transformers\"\n",
    ")"
   ],
   "id": "a1e740ae1f52a2a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine-tune GraphCodeBERT",
   "id": "cc9bd422c590282"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.training.train_codebert import train_multilabel_transformer\n",
    "\n",
    "train_multilabel_transformer(\n",
    "    model_name=\"microsoft/codebert-base\",\n",
    "    df=df,\n",
    "    label_cols=[\"Long Method\", \"God/Large Class\", \"Feature Envy\", \"Data Class\", \"Clean\"],\n",
    "    output_dir=\"../models/transformers\"\n",
    ")"
   ],
   "id": "3bac6e52f898ef13"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
