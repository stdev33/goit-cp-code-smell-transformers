# Applied Computer Science Project

Applied Computer Science Project at GoIT Neoversity

---

# Code Smell Detection using Self-Supervised Learning: A Study on Transformer-based Representations

This repository contains the implementation and experimental results of the Master's Thesis project at GoIT Neoversity titled:

**"Code Smell Detection using Self-Supervised Learning: A Study on Transformer-based Representations"**  
(Original Ukrainian title: â€œÐ’Ð¸ÑÐ²Ð»ÐµÐ½Ð½Ñ code smell Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ ÑÐ°Ð¼Ð¾Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ: Ð´Ð¾ÑÐ»Ñ–Ð´Ð¶ÐµÐ½Ð½Ñ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€Ð½Ð¸Ñ… Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½ÑŒâ€)

---

## ðŸ“Œ Project Overview

The goal of this project is to explore the effectiveness of Transformer-based models for automated detection of code smells in Java source code. The study focuses on comparing traditional machine learning models (e.g., Random Forest, XGBoost) with fine-tuned Transformer architectures (CodeBERT, GraphCodeBERT, CodeT5) trained on a merged dataset derived from the SmellyCode++[1] and CSQA[2] datasets.

---

## ðŸ§ª Features

- **Code Smell Types**: Long Method, Large/God Class, Feature Envy, Data Class
- **Model Types**:
  - Classical: Random Forest, XGBoost
  - Transformer-based: CodeBERT, GraphCodeBERT, CodeT5
- **Evaluation Metrics**: F1-score, Hamming Loss, Precision-Recall curves
- **Data Merging**: Combines structural metrics (CSQA) with raw code and labels (SmellyCode++) for multi-label classification
- **Inference Pipelines**: For both classical and transformer-based models

---

## ðŸ“ Project Structure

```
â”œâ”€â”€ data/                   # Raw, processed, and prediction datasets
â”œâ”€â”€ models/                 # Pretrained classical and Transformer models
â”œâ”€â”€ notebooks/             # Jupyter notebooks for training, evaluation, and analysis
â”œâ”€â”€ src/                    # Source code (data processing, training, inference modules)
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md
```

---

## ðŸ“Š Results

All transformer-based models demonstrated superior F1-scores across most smell categories, with CodeT5 performing best overall. Classical models still offer faster inference and decent results with engineered features.

Graphs and CSVs of predictions are available in the `data/images/` and `data/predictions/` folders respectively.

---

## âš™ï¸ Setup Instructions

1. Clone the repository:
   ```bash
   git clone https://github.com/YOUR_USERNAME/goit-cp-code-smell-transformers.git
   cd goit-cp-code-smell-transformers
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

---

## ðŸ§  Citation

If you use this project in your work, please cite it as:

> Tarasenko, Serhii. *Code Smell Detection using Self-Supervised Learning: A Study on Transformer-based Representations*. Masterâ€™s Thesis, GoIT Neoversity, 2025.
> 

---

## ðŸ“š References

[1] Alomari, N., Alazba, A., Aljamaan, H., & Alshayeb, M. (2025). *SmellyCode++.csv* (Version 1). figshare. https://doi.org/10.6084/m9.figshare.28519385.v1

[2] Esmaili, E., Zakeri, M., & Parsa, S. (2023). *Code smells and quality attributes dataset* (Version 2). figshare. https://doi.org/10.6084/m9.figshare.24057336.v2

---

## ðŸ”— Repository Link

The source code and models are available at:  
ðŸ‘‰ [https://github.com/stdev33/goit-cp-code-smell-transformers](https://github.com/stdev33/goit-cp-code-smell-transformers)

---